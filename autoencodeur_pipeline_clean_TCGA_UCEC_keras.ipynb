{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f223ad1",
   "metadata": {},
   "source": [
    "# Autoencodeur ‚Äì pipeline clean (Keras/TensorFlow)\n",
    "Ce notebook est une version **Keras** du pipeline autoencodeur, organis√©e comme un *mini-article* :\n",
    "\n",
    "1. **Donn√©es & alignement** (expression ‚Üî clinique)  \n",
    "2. **Construction de la cible** (Yes/No ‚Üí 1/0) et s√©paration *labellis√©s* / *non labellis√©s*  \n",
    "3. **Split patient-level** (stratifi√©) et **pr√©traitements sans fuite**  \n",
    "4. **Autoencodeur (Keras)** + early stopping  \n",
    "5. **Latent space (Z)** : extraction + visualisations 2D/3D  \n",
    "6. **√âvaluation downstream** : kNN sur **X_in** vs **Z** (ROC/PR + m√©triques)  \n",
    "7. **Cas illustratif** : un patient + ses K voisins (distances + outcomes)\n",
    "\n",
    "> ‚ö†Ô∏è Important : pour √©viter toute fuite, les transforms (scaler/PCA) et l‚Äôautoencodeur sont **fit uniquement sur le set d‚Äôentra√Ænement AE**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e685ec1",
   "metadata": {},
   "source": [
    "## 0) Setup & param√®tres\n",
    "- Mets ici les chemins vers tes fichiers (expression + meta).\n",
    "- Adapte les noms de colonnes d‚ÄôID si besoin.\n",
    "- Choisis si tu veux entra√Æner l‚Äôautoencodeur aussi sur les patients **non labellis√©s** (souvent utile en semi-supervis√© non param√©trique).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31524c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Imports ---\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, f1_score, balanced_accuracy_score,\n",
    "    RocCurveDisplay, PrecisionRecallDisplay\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# --- Reproductibilit√© ---\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# --- I/O ---\n",
    "EXPR_PATH = r\"PATH/TO/expression.csv\"   # ex: matrice (patients x g√®nes)\n",
    "META_PATH = r\"PATH/TO/meta.csv\"         # ex: table clinique\n",
    "\n",
    "# Colonnes d'ID √† adapter √† ton format\n",
    "EXPR_ID_COL = \"patient\"                 # ou \"barcode\"/\"submitter_id\"/etc.\n",
    "META_ID_COL = \"patient\"\n",
    "\n",
    "TARGET_COL  = \"paper_recurred_progressed\"\n",
    "\n",
    "# --- Hyperparams ---\n",
    "TEST_SIZE = 0.20\n",
    "LATENT_DIM = 32\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 300\n",
    "PATIENCE = 25\n",
    "\n",
    "# R√©duction de dimension avant AE (souvent indispensable avec 21k g√®nes)\n",
    "USE_PCA = True\n",
    "PCA_NCOMP = 512     # 256‚Äì1024 typiquement\n",
    "\n",
    "# Entra√Æner AE aussi sur les non-labellis√©s (recommand√© si beaucoup de non labellis√©s)\n",
    "INCLUDE_UNLABELED_IN_AE_TRAIN = True\n",
    "\n",
    "# kNN downstream\n",
    "K_NEIGHBORS = 10\n",
    "\n",
    "# Dossier figures\n",
    "FIGDIR = \"figures_autoencoder_keras\"\n",
    "os.makedirs(FIGDIR, exist_ok=True)\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a80f407",
   "metadata": {},
   "source": [
    "## 1) Chargement & alignement patient-level\n",
    "On charge :\n",
    "- une matrice d‚Äôexpression (patients √ó g√®nes)\n",
    "- une table `meta` (patients √ó variables cliniques)\n",
    "\n",
    "Puis on aligne les patients sur l‚Äôintersection des IDs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b040806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Chargement ---\n",
    "# ‚ö†Ô∏è adapte read_csv / index_col selon tes fichiers\n",
    "expr = pd.read_csv(EXPR_PATH)\n",
    "meta = pd.read_csv(META_PATH)\n",
    "\n",
    "# Si tes matrices sont d√©j√† index√©es par patient, tu peux faire :\n",
    "# expr = pd.read_csv(EXPR_PATH, index_col=0)\n",
    "# expr.index.name = EXPR_ID_COL\n",
    "\n",
    "# Ici, on suppose qu'il y a une colonne ID dans expr\n",
    "assert EXPR_ID_COL in expr.columns, f\"Colonne {EXPR_ID_COL} absente dans expr\"\n",
    "assert META_ID_COL in meta.columns, f\"Colonne {META_ID_COL} absente dans meta\"\n",
    "\n",
    "expr = expr.set_index(EXPR_ID_COL)\n",
    "meta = meta.set_index(META_ID_COL)\n",
    "\n",
    "# Alignement IDs (intersection)\n",
    "common_ids = expr.index.intersection(meta.index)\n",
    "expr = expr.loc[common_ids].copy()\n",
    "meta = meta.loc[common_ids].copy()\n",
    "\n",
    "print(\"N patients align√©s:\", len(common_ids))\n",
    "print(\"Expr shape (patients x features):\", expr.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf1a8ce",
   "metadata": {},
   "source": [
    "## 2) Construction de la cible (y) + masques\n",
    "On mappe `Yes/No` ‚Üí `1/0`.  \n",
    "Ensuite :\n",
    "- `idx_labeled` : patients avec y connu\n",
    "- `idx_unlabeled` : y manquant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e47ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- y binaire propre ---\n",
    "y_str = meta[TARGET_COL].astype(str).str.strip().str.lower()\n",
    "y = y_str.map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "mask_labeled = y.notna().to_numpy()\n",
    "idx_labeled = np.where(mask_labeled)[0]\n",
    "idx_unlabeled = np.where(~mask_labeled)[0]\n",
    "\n",
    "print(f\"Total: {len(y)}\")\n",
    "print(f\"Labeled: {len(idx_labeled)} | Unlabeled: {len(idx_unlabeled)}\")\n",
    "\n",
    "# X complet (pour encoder tout le monde ensuite)\n",
    "X_all = expr.to_numpy(dtype=np.float32)\n",
    "\n",
    "# y pour les labellis√©s uniquement\n",
    "y_labeled = y.iloc[idx_labeled].to_numpy(dtype=np.int32)\n",
    "print(\"Positifs:\", int(y_labeled.sum()), \"/\", len(y_labeled), f\"({y_labeled.mean()*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19249aec",
   "metadata": {},
   "source": [
    "## 3) Split patient-level (stratifi√©) + sets AE/train/test\n",
    "On fait le split **uniquement** sur les patients labellis√©s (car il faut `stratify=y`).  \n",
    "Puis on d√©finit :\n",
    "\n",
    "- `idx_test` : labellis√©s test  \n",
    "- `idx_train_lab` : labellis√©s train  \n",
    "- `idx_train_ae` : set d‚Äôentra√Ænement de l‚Äôautoencodeur (train labellis√©s + √©ventuellement non labellis√©s)\n",
    "\n",
    "üëâ L‚ÄôAE **ne voit jamais** les patients du test, pour √©viter toute fuite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Indices relatifs √† la liste idx_labeled\n",
    "rel_all = np.arange(len(idx_labeled))\n",
    "rel_train, rel_test = train_test_split(\n",
    "    rel_all, test_size=TEST_SIZE, random_state=SEED, stratify=y_labeled\n",
    ")\n",
    "\n",
    "idx_train_lab = idx_labeled[rel_train]\n",
    "idx_test      = idx_labeled[rel_test]\n",
    "\n",
    "if INCLUDE_UNLABELED_IN_AE_TRAIN:\n",
    "    idx_train_ae = np.concatenate([idx_train_lab, idx_unlabeled])\n",
    "else:\n",
    "    idx_train_ae = idx_train_lab.copy()\n",
    "\n",
    "print(\"Train labeled:\", len(idx_train_lab))\n",
    "print(\"Test labeled :\", len(idx_test))\n",
    "print(\"Train AE     :\", len(idx_train_ae))\n",
    "\n",
    "# Sanity: pas d'intersection train_ae / test\n",
    "assert len(np.intersect1d(idx_train_ae, idx_test)) == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eee7d3c",
   "metadata": {},
   "source": [
    "## 4) Pr√©traitements sans fuite (scaler + PCA optionnel)\n",
    "- **Scaler** fit sur `idx_train_ae` uniquement.\n",
    "- **PCA** (si activ√©) fit sur `idx_train_ae` uniquement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea94ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- scaler ---\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_ae_scaled = scaler.fit_transform(X_all[idx_train_ae])\n",
    "\n",
    "X_all_scaled = scaler.transform(X_all)  # transform sur tous, mais scaler fit sur train_ae\n",
    "\n",
    "# --- PCA (optionnelle) ---\n",
    "if USE_PCA:\n",
    "    pca = PCA(n_components=PCA_NCOMP, random_state=SEED)\n",
    "    X_train_ae_in = pca.fit_transform(X_train_ae_scaled)\n",
    "    X_all_in      = pca.transform(X_all_scaled)\n",
    "    input_dim = X_train_ae_in.shape[1]\n",
    "    explained = pca.explained_variance_ratio_.sum()\n",
    "    print(f\"PCA: input_dim={input_dim} | variance expliqu√©e ~ {explained:.2f}\")\n",
    "else:\n",
    "    X_train_ae_in = X_train_ae_scaled\n",
    "    X_all_in      = X_all_scaled\n",
    "    input_dim = X_train_ae_in.shape[1]\n",
    "    print(f\"No PCA: input_dim={input_dim}\")\n",
    "\n",
    "# X_in pour train/test labellis√©s (downstream)\n",
    "X_train_in = X_all_in[idx_train_lab]\n",
    "X_test_in  = X_all_in[idx_test]\n",
    "y_train    = y.iloc[idx_train_lab].to_numpy(dtype=np.int32)\n",
    "y_test     = y.iloc[idx_test].to_numpy(dtype=np.int32)\n",
    "\n",
    "print(\"X_train_in:\", X_train_in.shape, \"| X_test_in:\", X_test_in.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967dd51d",
   "metadata": {},
   "source": [
    "## 5) Autoencodeur (Keras)\n",
    "Architecture Dense sym√©trique :\n",
    "- Encodeur : 512 ‚Üí 256 ‚Üí `LATENT_DIM`\n",
    "- D√©codeur : 256 ‚Üí 512 ‚Üí reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_autoencoder(input_dim: int, latent_dim: int = 32, dropout: float = 0.1):\n",
    "    inp = keras.Input(shape=(input_dim,), name=\"X_in\")\n",
    "\n",
    "    x = layers.Dense(512)(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "\n",
    "    x = layers.Dense(256)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "\n",
    "    z = layers.Dense(latent_dim, name=\"Z\")(x)\n",
    "\n",
    "    x = layers.Dense(256)(z)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "\n",
    "    x = layers.Dense(512)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "\n",
    "    out = layers.Dense(input_dim, name=\"X_recon\")(x)\n",
    "\n",
    "    auto = keras.Model(inp, out, name=\"autoencoder\")\n",
    "    encoder = keras.Model(inp, z, name=\"encoder\")\n",
    "\n",
    "    auto.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mse\")\n",
    "    return auto, encoder\n",
    "\n",
    "autoencoder, encoder = build_autoencoder(input_dim=input_dim, latent_dim=LATENT_DIM, dropout=0.15)\n",
    "autoencoder.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=8, factor=0.5, min_lr=1e-5)\n",
    "]\n",
    "\n",
    "history = autoencoder.fit(\n",
    "    X_train_ae_in, X_train_ae_in,\n",
    "    validation_split=0.1,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Figure : learning curves ---\n",
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"], label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE reconstruction\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"Fig1_training_curve.png\"), dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff13e0b",
   "metadata": {},
   "source": [
    "## 6) Extraction du latent space Z + reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aba0760",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Encodage ---\n",
    "Z_all = encoder.predict(X_all_in, batch_size=512, verbose=0)\n",
    "\n",
    "# --- Reconstruction error ---\n",
    "X_recon = autoencoder.predict(X_all_in, batch_size=512, verbose=0)\n",
    "recon_err = np.mean((X_all_in - X_recon)**2, axis=1)\n",
    "\n",
    "print(\"Z_all:\", Z_all.shape)\n",
    "print(\"Recon err: mean\", float(np.mean(recon_err)), \"std\", float(np.std(recon_err)))\n",
    "\n",
    "# --- Figure : distribution recon error ---\n",
    "plt.figure()\n",
    "plt.hist(recon_err, bins=50)\n",
    "plt.xlabel(\"Reconstruction error (MSE)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"Fig2_recon_error_hist.png\"), dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# --- Figure : recon error par label (labellis√©s uniquement) ---\n",
    "plt.figure()\n",
    "plt.hist(recon_err[idx_labeled][y_labeled==0], bins=40, alpha=0.7, label=\"No\")\n",
    "plt.hist(recon_err[idx_labeled][y_labeled==1], bins=40, alpha=0.7, label=\"Yes\")\n",
    "plt.xlabel(\"Reconstruction error (MSE)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"Fig2b_recon_error_by_label.png\"), dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1b0617",
   "metadata": {},
   "source": [
    "## 7) Visualisation du latent space (Z) ‚Äì 2D & 3D (PCA sur Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83395d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pcaZ2 = PCA(n_components=2, random_state=SEED)\n",
    "Z2 = pcaZ2.fit_transform(Z_all)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(Z2[:,0], Z2[:,1], s=10, alpha=0.6)\n",
    "plt.xlabel(\"PC1 (Z)\")\n",
    "plt.ylabel(\"PC2 (Z)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"Fig3_Z_PCA2_all.png\"), dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# Color√© par label (labellis√©s seulement)\n",
    "plt.figure()\n",
    "mask0 = (y.iloc[idx_labeled].to_numpy()==0)\n",
    "mask1 = (y.iloc[idx_labeled].to_numpy()==1)\n",
    "plt.scatter(Z2[idx_labeled][mask0,0], Z2[idx_labeled][mask0,1], s=12, alpha=0.6, label=\"No\")\n",
    "plt.scatter(Z2[idx_labeled][mask1,0], Z2[idx_labeled][mask1,1], s=12, alpha=0.6, label=\"Yes\")\n",
    "plt.xlabel(\"PC1 (Z)\")\n",
    "plt.ylabel(\"PC2 (Z)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"Fig3b_Z_PCA2_labeled.png\"), dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# 3D\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "pcaZ3 = PCA(n_components=3, random_state=SEED)\n",
    "Z3 = pcaZ3.fit_transform(Z_all)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.scatter(Z3[:,0], Z3[:,1], Z3[:,2], s=8, alpha=0.5)\n",
    "ax.set_xlabel(\"PC1 (Z)\")\n",
    "ax.set_ylabel(\"PC2 (Z)\")\n",
    "ax.set_zlabel(\"PC3 (Z)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"Fig3c_Z_PCA3_all.png\"), dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fd2d5f",
   "metadata": {},
   "source": [
    "## 8) Downstream : kNN sur X_in vs kNN sur Z (ROC/PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da20ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_knn(Xtr, Xte, ytr, yte, k=10):\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, weights=\"distance\")\n",
    "    clf.fit(Xtr, ytr)\n",
    "    proba = clf.predict_proba(Xte)[:,1]\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "    out = {\n",
    "        \"ROC_AUC\": roc_auc_score(yte, proba) if len(np.unique(yte))==2 else np.nan,\n",
    "        \"PR_AUC\": average_precision_score(yte, proba) if len(np.unique(yte))==2 else np.nan,\n",
    "        \"F1\": f1_score(yte, pred, zero_division=0),\n",
    "        \"BalAcc\": balanced_accuracy_score(yte, pred),\n",
    "        \"proba\": proba,\n",
    "        \"pred\": pred\n",
    "    }\n",
    "    return out\n",
    "\n",
    "res_X = eval_knn(X_train_in, X_test_in, y_train, y_test, k=K_NEIGHBORS)\n",
    "\n",
    "Z_train = Z_all[idx_train_lab]\n",
    "Z_test  = Z_all[idx_test]\n",
    "res_Z = eval_knn(Z_train, Z_test, y_train, y_test, k=K_NEIGHBORS)\n",
    "\n",
    "print(\"kNN on X_in:\", {k:v for k,v in res_X.items() if k not in (\"proba\",\"pred\")})\n",
    "print(\"kNN on Z   :\", {k:v for k,v in res_Z.items() if k not in (\"proba\",\"pred\")})\n",
    "\n",
    "# ROC\n",
    "plt.figure()\n",
    "RocCurveDisplay.from_predictions(y_test, res_X[\"proba\"], name=\"kNN on X_in\")\n",
    "RocCurveDisplay.from_predictions(y_test, res_Z[\"proba\"], name=\"kNN on Z\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"Fig4_ROC_X_vs_Z.png\"), dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# PR\n",
    "plt.figure()\n",
    "PrecisionRecallDisplay.from_predictions(y_test, res_X[\"proba\"], name=\"kNN on X_in\")\n",
    "PrecisionRecallDisplay.from_predictions(y_test, res_Z[\"proba\"], name=\"kNN on Z\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"Fig4b_PR_X_vs_Z.png\"), dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbac44e",
   "metadata": {},
   "source": [
    "## 9) Cas illustratif : un patient test + ses K voisins en Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ba1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Choisir un patient du test (ex: le premier)\n",
    "i_test = 0\n",
    "idx_patient = idx_test[i_test]\n",
    "\n",
    "# Voisins cherch√©s dans le TRAIN labellis√© (sinon fuite)\n",
    "nbrs = NearestNeighbors(n_neighbors=K_NEIGHBORS, metric=\"euclidean\")\n",
    "nbrs.fit(Z_train)\n",
    "\n",
    "dist, ind = nbrs.kneighbors(Z_all[idx_patient].reshape(1,-1))\n",
    "dist = dist.flatten()\n",
    "ind = ind.flatten()\n",
    "\n",
    "neighbor_idx_global = idx_train_lab[ind]\n",
    "neighbor_y = y.iloc[neighbor_idx_global].to_numpy(dtype=int)\n",
    "\n",
    "# Pr√©diction simple : moyenne pond√©r√©e (inverse distance)\n",
    "w = 1.0 / (dist + 1e-6)\n",
    "pred_risk = float(np.sum(w * neighbor_y) / np.sum(w))\n",
    "\n",
    "print(\"Patient index (global):\", idx_patient)\n",
    "print(\"Predicted risk (neighbors):\", pred_risk)\n",
    "print(\"Neighbors positives:\", int(neighbor_y.sum()), \"/\", len(neighbor_y))\n",
    "\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.bar(np.arange(len(dist)), dist)\n",
    "plt.xlabel(\"Neighbor rank\")\n",
    "plt.ylabel(\"Distance in Z\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"Fig5_patient_neighbor_distances.png\"), dpi=200)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,2.6))\n",
    "plt.bar(np.arange(len(neighbor_y)), neighbor_y)\n",
    "plt.yticks([0,1], [\"No\",\"Yes\"])\n",
    "plt.xlabel(\"Neighbor rank\")\n",
    "plt.title(f\"Neighbor labels (Yes=1) | predicted risk={pred_risk:.2f}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"Fig5b_patient_neighbor_labels.png\"), dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# Afficher IDs si dispo\n",
    "patient_id = expr.index[idx_patient]\n",
    "neighbor_ids = expr.index[neighbor_idx_global]\n",
    "display(pd.DataFrame({\"neighbor_id\": neighbor_ids, \"distance\": dist, \"y\": neighbor_y}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c35e23",
   "metadata": {},
   "source": [
    "## 10) Export (optionnel) : Z + recon_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e844bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = pd.DataFrame(Z_all, index=expr.index, columns=[f\"Z{i+1}\" for i in range(Z_all.shape[1])])\n",
    "out[\"recon_err\"] = recon_err\n",
    "out[\"y\"] = y  # NaN pour non labellis√©s\n",
    "\n",
    "OUT_CSV = \"latent_Z_keras.csv\"\n",
    "out.to_csv(OUT_CSV)\n",
    "print(\"Saved:\", OUT_CSV)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
